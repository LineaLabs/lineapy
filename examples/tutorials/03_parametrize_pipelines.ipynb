{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e19140de",
            "metadata": {},
            "source": [
                "# Building Parametrized Pipelines"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef729a30",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "This tutorial is a sequel to `02_build_pipelines.ipynb` and will need artifacts and files stored from it. Please ensure `02_build_pipelines.ipynb` has been run before running this tutorial.\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f02179fb",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "If you encounter issues you cannot resolve, simply ask in our [Slack community](https://join.slack.com/t/lineacommunity/shared_invite/zt-18kizfn3b-1Qu_HDT3ahGudnAwoFAw9Q)'s `#support` channel. We are always happy and ready to help you!\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3485e175",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "You can ignore `# NBVAL_*` comments in certain cell blocks. They are for passing unit tests only, which we do to make sure the examples are always functional as we update the codebase.\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "905330ee",
            "metadata": {},
            "source": [
                "Oftentimes, data scientists/engineers need to run the same pipeline with different parameters. For instance, they may want to use a different data set for model training and/or prediction. To produce a parametrized pipeline, we can use pipeline API’s (optional) `input_parameters` argument."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "183ed120",
            "metadata": {},
            "outputs": [],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "import lineapy\n",
                "lineapy.tag(\"Building Parameterized Pipelines Demo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "618278a8",
            "metadata": {},
            "source": [
                "As a concrete example, consider the pipeline created in `02_build_pipelines.ipynb`, where we got an “inflexible” pipeline that has the data source (url) as a fixed value:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c578f119",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "import pandas as pd\r\n",
                        "from sklearn.linear_model import LinearRegression\r\n",
                        "\r\n",
                        "\r\n",
                        "def get_iris_preprocessed():\r\n",
                        "    url = \"https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv\"\r\n",
                        "    df = pd.read_csv(url)\r\n",
                        "    color_map = {\"Setosa\": \"green\", \"Versicolor\": \"blue\", \"Virginica\": \"red\"}\r\n",
                        "    df[\"variety_color\"] = df[\"variety\"].map(color_map)\r\n",
                        "    df[\"d_versicolor\"] = df[\"variety\"].apply(lambda x: 1 if x == \"Versicolor\" else 0)\r\n",
                        "    df[\"d_virginica\"] = df[\"variety\"].apply(lambda x: 1 if x == \"Virginica\" else 0)\r\n",
                        "    return df\r\n",
                        "\r\n",
                        "\r\n",
                        "def get_iris_model(df):\r\n",
                        "    mod = LinearRegression()\r\n",
                        "    mod.fit(\r\n",
                        "        X=df[[\"petal.width\", \"d_versicolor\", \"d_virginica\"]],\r\n",
                        "        y=df[\"sepal.width\"],\r\n",
                        "    )\r\n",
                        "    return mod\r\n",
                        "\r\n",
                        "\r\n",
                        "def run_session_including_iris_preprocessed():\r\n",
                        "    # Given multiple artifacts, we need to save each right after\r\n",
                        "    # its calculation to protect from any irrelevant downstream\r\n",
                        "    # mutations (e.g., inside other artifact calculations)\r\n",
                        "    import copy\r\n",
                        "\r\n",
                        "    artifacts = dict()\r\n",
                        "    df = get_iris_preprocessed()\r\n",
                        "    artifacts[\"iris_preprocessed\"] = copy.deepcopy(df)\r\n",
                        "    mod = get_iris_model(df)\r\n",
                        "    artifacts[\"iris_model\"] = copy.deepcopy(mod)\r\n",
                        "    return artifacts\r\n",
                        "\r\n",
                        "\r\n",
                        "def run_all_sessions():\r\n",
                        "    artifacts = dict()\r\n",
                        "    artifacts.update(run_session_including_iris_preprocessed())\r\n",
                        "    return artifacts\r\n",
                        "\r\n",
                        "\r\n",
                        "if __name__ == \"__main__\":\r\n",
                        "    # Edit this section to customize the behavior of artifacts\r\n",
                        "    artifacts = run_all_sessions()\r\n",
                        "    print(artifacts)\r\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "%cat ./output/pipeline_basics/iris_pipeline_module.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e50925c3",
            "metadata": {},
            "source": [
                "Instead, we can run:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "f755265f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Generated module file: output/pipeline_parametrization/iris_pipeline_parametrized_module.py                                                                                                                  \n",
                        "Generated requirements file: output/pipeline_parametrization/iris_pipeline_parametrized_requirements.txt                                                                                                     \n",
                        "Generated DAG file: output/pipeline_parametrization/iris_pipeline_parametrized_dag.py                                                                                                                        \n",
                        "Generated Docker file: output/pipeline_parametrization/iris_pipeline_parametrized_Dockerfile                                                                                                                 \n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "PosixPath('output/pipeline_parametrization')"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "\n",
                "# Build an Airflow pipeline using artifacts\n",
                "lineapy.to_pipeline(\n",
                "    pipeline_name=\"iris_pipeline_parametrized\",\n",
                "    artifacts=[\"iris_preprocessed\", \"iris_model\"],\n",
                "    dependencies={\"iris_model\": {\"iris_preprocessed\"}},\n",
                "    input_parameters=[\"url\"],  # Specify variable(s) to parametrize\n",
                "    output_dir=\"./output/pipeline_parametrization/\",\n",
                "    framework=\"AIRFLOW\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c88ce59b",
            "metadata": {},
            "source": [
                "to get a parametrized pipline, like so:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "023ceb5f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "import argparse\r\n",
                        "\r\n",
                        "import pandas as pd\r\n",
                        "from sklearn.linear_model import LinearRegression\r\n",
                        "\r\n",
                        "\r\n",
                        "def get_iris_preprocessed(url):\r\n",
                        "    df = pd.read_csv(url)\r\n",
                        "    color_map = {\"Setosa\": \"green\", \"Versicolor\": \"blue\", \"Virginica\": \"red\"}\r\n",
                        "    df[\"variety_color\"] = df[\"variety\"].map(color_map)\r\n",
                        "    df[\"d_versicolor\"] = df[\"variety\"].apply(lambda x: 1 if x == \"Versicolor\" else 0)\r\n",
                        "    df[\"d_virginica\"] = df[\"variety\"].apply(lambda x: 1 if x == \"Virginica\" else 0)\r\n",
                        "    return df\r\n",
                        "\r\n",
                        "\r\n",
                        "def get_iris_model(df):\r\n",
                        "    mod = LinearRegression()\r\n",
                        "    mod.fit(\r\n",
                        "        X=df[[\"petal.width\", \"d_versicolor\", \"d_virginica\"]],\r\n",
                        "        y=df[\"sepal.width\"],\r\n",
                        "    )\r\n",
                        "    return mod\r\n",
                        "\r\n",
                        "\r\n",
                        "def run_session_including_iris_preprocessed(\r\n",
                        "    url=\"https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv\",\r\n",
                        "):\r\n",
                        "    # Given multiple artifacts, we need to save each right after\r\n",
                        "    # its calculation to protect from any irrelevant downstream\r\n",
                        "    # mutations (e.g., inside other artifact calculations)\r\n",
                        "    import copy\r\n",
                        "\r\n",
                        "    artifacts = dict()\r\n",
                        "    df = get_iris_preprocessed(url)\r\n",
                        "    artifacts[\"iris_preprocessed\"] = copy.deepcopy(df)\r\n",
                        "    mod = get_iris_model(df)\r\n",
                        "    artifacts[\"iris_model\"] = copy.deepcopy(mod)\r\n",
                        "    return artifacts\r\n",
                        "\r\n",
                        "\r\n",
                        "def run_all_sessions(\r\n",
                        "    url=\"https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv\",\r\n",
                        "):\r\n",
                        "    artifacts = dict()\r\n",
                        "    artifacts.update(run_session_including_iris_preprocessed(url))\r\n",
                        "    return artifacts\r\n",
                        "\r\n",
                        "\r\n",
                        "if __name__ == \"__main__\":\r\n",
                        "    # Edit this section to customize the behavior of artifacts\r\n",
                        "    parser = argparse.ArgumentParser()\r\n",
                        "    parser.add_argument(\r\n",
                        "        \"--url\",\r\n",
                        "        type=str,\r\n",
                        "        default=\"https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv\",\r\n",
                        "    )\r\n",
                        "    args = parser.parse_args()\r\n",
                        "    artifacts = run_all_sessions(\r\n",
                        "        url=args.url,\r\n",
                        "    )\r\n",
                        "    print(artifacts)\r\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "%cat ./output/pipeline_parametrization/iris_pipeline_parametrized_module.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6b4f39cc",
            "metadata": {},
            "source": [
                "As shown, we now have url factored out as an easily tunable parameter for the pipeline, which allows us to run it with various data sources beyond those we started with (hence increasing the pipeline’s utility)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "18728134",
            "metadata": {},
            "source": [
                "Note that we get parametrization reflected in the framework-specific DAG file as well:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "e0903341",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "import pathlib\r\n",
                        "import pickle\r\n",
                        "\r\n",
                        "import iris_pipeline_parametrized_module\r\n",
                        "from airflow import DAG\r\n",
                        "from airflow.operators.python_operator import PythonOperator\r\n",
                        "from airflow.utils.dates import days_ago\r\n",
                        "\r\n",
                        "\r\n",
                        "def dag_setup():\r\n",
                        "    pickle_folder = pathlib.Path(\"/tmp\").joinpath(\"iris_pipeline_parametrized\")\r\n",
                        "    if not pickle_folder.exists():\r\n",
                        "        pickle_folder.mkdir()\r\n",
                        "\r\n",
                        "\r\n",
                        "def dag_teardown():\r\n",
                        "    pickle_files = (\r\n",
                        "        pathlib.Path(\"/tmp\").joinpath(\"iris_pipeline_parametrized\").glob(\"*.pickle\")\r\n",
                        "    )\r\n",
                        "    for f in pickle_files:\r\n",
                        "        f.unlink()\r\n",
                        "\r\n",
                        "\r\n",
                        "def task_iris_preprocessed(url):\r\n",
                        "\r\n",
                        "    url = str(url)\r\n",
                        "\r\n",
                        "    df = iris_pipeline_parametrized_module.get_iris_preprocessed(url)\r\n",
                        "\r\n",
                        "    pickle.dump(df, open(\"/tmp/iris_pipeline_parametrized/variable_df.pickle\", \"wb\"))\r\n",
                        "\r\n",
                        "\r\n",
                        "def task_iris_model():\r\n",
                        "\r\n",
                        "    df = pickle.load(open(\"/tmp/iris_pipeline_parametrized/variable_df.pickle\", \"rb\"))\r\n",
                        "\r\n",
                        "    mod = iris_pipeline_parametrized_module.get_iris_model(df)\r\n",
                        "\r\n",
                        "    pickle.dump(mod, open(\"/tmp/iris_pipeline_parametrized/variable_mod.pickle\", \"wb\"))\r\n",
                        "\r\n",
                        "\r\n",
                        "default_dag_args = {\r\n",
                        "    \"owner\": \"airflow\",\r\n",
                        "    \"retries\": 2,\r\n",
                        "    \"start_date\": days_ago(1),\r\n",
                        "    \"params\": {\r\n",
                        "        \"url\": \"https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv\"\r\n",
                        "    },\r\n",
                        "}\r\n",
                        "\r\n",
                        "with DAG(\r\n",
                        "    dag_id=\"iris_pipeline_parametrized_dag\",\r\n",
                        "    schedule_interval=\"*/15 * * * *\",\r\n",
                        "    max_active_runs=1,\r\n",
                        "    catchup=False,\r\n",
                        "    default_args=default_dag_args,\r\n",
                        ") as dag:\r\n",
                        "\r\n",
                        "    setup = PythonOperator(\r\n",
                        "        task_id=\"dag_setup\",\r\n",
                        "        python_callable=dag_setup,\r\n",
                        "    )\r\n",
                        "\r\n",
                        "    teardown = PythonOperator(\r\n",
                        "        task_id=\"dag_teardown\",\r\n",
                        "        python_callable=dag_teardown,\r\n",
                        "    )\r\n",
                        "\r\n",
                        "    iris_preprocessed = PythonOperator(\r\n",
                        "        task_id=\"iris_preprocessed_task\",\r\n",
                        "        python_callable=task_iris_preprocessed,\r\n",
                        "        op_kwargs={\"url\": \"{{ params.url }}\"},\r\n",
                        "    )\r\n",
                        "\r\n",
                        "    iris_model = PythonOperator(\r\n",
                        "        task_id=\"iris_model_task\",\r\n",
                        "        python_callable=task_iris_model,\r\n",
                        "    )\r\n",
                        "\r\n",
                        "    iris_preprocessed >> iris_model\r\n",
                        "\r\n",
                        "    setup >> iris_preprocessed\r\n",
                        "\r\n",
                        "    iris_model >> teardown\r\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "%cat ./output/pipeline_parametrization/iris_pipeline_parametrized_dag.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ab1318db",
            "metadata": {},
            "source": [
                "Hence, we can easily modify pipeline runs in the target system (Airflow in this case)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "954f56eb",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-warning\">\n",
                "\n",
                "Currently, `input_parameters` only accepts variables from literal assignment such as `a = \"123\"`. For each variable to be parametrized, there should be only one literal assignment across all artifact code for the pipeline. For instance, if both `a = \"123\"` and `a = \"abc\"` exist in the pipeline's artifact code, we cannot make `a` an input parameter since its reference is ambiguous, i.e., we are not sure which literal assignment `a` refers to.\n",
                "\n",
                "</div>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}