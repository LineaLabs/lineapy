{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "e19140de",
            "metadata": {},
            "source": [
                "# Testing Pipelines"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef729a30",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "This tutorial is a sequel to `02a_build_pipelines.ipynb` and will need artifacts and files stored from it. Please ensure `02a_build_pipelines.ipynb` has been run before running this tutorial.\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f02179fb",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "If you encounter issues you cannot resolve, simply ask in our [Slack community](https://join.slack.com/t/lineacommunity/shared_invite/zt-18kizfn3b-1Qu_HDT3ahGudnAwoFAw9Q)'s `#support` channel. We are always happy and ready to help you!\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3485e175",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "You can ignore `# NBVAL_*` comments in certain cell blocks. They are for passing unit tests only, which we do to make sure the examples are always functional as we update the codebase.\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "905330ee",
            "metadata": {},
            "source": [
                "When building a pipeline, LineaPy transforms the user's original code into modularized functions\n",
                "where extraneous operations are removed. With such changes, the user may want to ensure that the\n",
                "transformed code is valid and reliable before actually using it. To support this, LineaPy's pipeline\n",
                "API provides an optional ``generate_test`` argument (default set to ``False``)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "183ed120",
            "metadata": {},
            "outputs": [],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "import lineapy\n",
                "lineapy.tag(\"Pipeline Testing Demo\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "618278a8",
            "metadata": {},
            "source": [
                "As a concrete example, consider the pipeline created in `02a_build_pipelines.ipynb`, where we got the following modularized code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c578f119",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "import pandas as pd\r\n",
                        "from sklearn.linear_model import LinearRegression\r\n",
                        "\r\n",
                        "\r\n",
                        "def get_iris_preprocessed():\r\n",
                        "    url = \"https://raw.githubusercontent.com/LineaLabs/lineapy/main/examples/tutorials/data/iris.csv\"\r\n",
                        "    df = pd.read_csv(url)\r\n",
                        "    color_map = {\"Setosa\": \"green\", \"Versicolor\": \"blue\", \"Virginica\": \"red\"}\r\n",
                        "    df[\"variety_color\"] = df[\"variety\"].map(color_map)\r\n",
                        "    df[\"d_versicolor\"] = df[\"variety\"].apply(lambda x: 1 if x == \"Versicolor\" else 0)\r\n",
                        "    df[\"d_virginica\"] = df[\"variety\"].apply(lambda x: 1 if x == \"Virginica\" else 0)\r\n",
                        "    return df\r\n",
                        "\r\n",
                        "\r\n",
                        "def get_iris_model(df):\r\n",
                        "    mod = LinearRegression()\r\n",
                        "    mod.fit(\r\n",
                        "        X=df[[\"petal.width\", \"d_versicolor\", \"d_virginica\"]],\r\n",
                        "        y=df[\"sepal.width\"],\r\n",
                        "    )\r\n",
                        "    return mod\r\n",
                        "\r\n",
                        "\r\n",
                        "def run_session_including_iris_preprocessed():\r\n",
                        "    # Given multiple artifacts, we need to save each right after\r\n",
                        "    # its calculation to protect from any irrelevant downstream\r\n",
                        "    # mutations (e.g., inside other artifact calculations)\r\n",
                        "    import copy\r\n",
                        "\r\n",
                        "    artifacts = dict()\r\n",
                        "    df = get_iris_preprocessed()\r\n",
                        "    artifacts[\"iris_preprocessed\"] = copy.deepcopy(df)\r\n",
                        "    mod = get_iris_model(df)\r\n",
                        "    artifacts[\"iris_model\"] = copy.deepcopy(mod)\r\n",
                        "    return artifacts\r\n",
                        "\r\n",
                        "\r\n",
                        "def run_all_sessions():\r\n",
                        "    artifacts = dict()\r\n",
                        "    artifacts.update(run_session_including_iris_preprocessed())\r\n",
                        "    return artifacts\r\n",
                        "\r\n",
                        "\r\n",
                        "if __name__ == \"__main__\":\r\n",
                        "    # Edit this section to customize the behavior of artifacts\r\n",
                        "    artifacts = run_all_sessions()\r\n",
                        "    print(artifacts)\r\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "%cat ./output/pipeline_basics/iris_pipeline_module.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7f1eb228",
            "metadata": {},
            "source": [
                "## Generating Pipeline Test"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e50925c3",
            "metadata": {},
            "source": [
                "Now, had we run:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "f755265f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Generated module file: output/pipeline_basics/iris_pipeline_module.py                                                                                                                                \n",
                        "Generated requirements file: output/pipeline_basics/iris_pipeline_requirements.txt                                                                                                                   \n",
                        "Generated DAG file: output/pipeline_basics/iris_pipeline_dag.py                                                                                                                                      \n",
                        "Generated Docker file: output/pipeline_basics/iris_pipeline_Dockerfile                                                                                                                               \n",
                        "Generated test scaffold file: output/pipeline_basics/test_iris_pipeline.py                                                                                                                           \n",
                        "Generated tests are provided as template/scaffold to start with only; please modify them to suit your testing needs. Also, tests may involve long compute and/or large storage, so please take care  \n",
                        "in running them.                                                                                                                                                                                     \n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "PosixPath('output/pipeline_basics')"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "\n",
                "# Build an Airflow pipeline using artifacts\n",
                "lineapy.to_pipeline(\n",
                "  pipeline_name=\"iris_pipeline\",\n",
                "  artifacts=[\"iris_preprocessed\", \"iris_model\"],\n",
                "  dependencies={\"iris_model\": {\"iris_preprocessed\"}},\n",
                "  output_dir=\"./output/pipeline_basics/\",\n",
                "  framework=\"AIRFLOW\",\n",
                "  generate_test=True,  # Optional\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c88ce59b",
            "metadata": {},
            "source": [
                "we would have had the following file generated too for testing the modularized code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "023ceb5f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "import os\r\n",
                        "import pickle\r\n",
                        "import unittest\r\n",
                        "import warnings\r\n",
                        "from pathlib import Path\r\n",
                        "from typing import Callable\r\n",
                        "\r\n",
                        "from iris_pipeline_module import get_iris_model, get_iris_preprocessed\r\n",
                        "\r\n",
                        "\r\n",
                        "def safe_load_pickle(\r\n",
                        "    path_to_file: Path,\r\n",
                        "    alt_val_func: Callable = lambda: FileNotFoundError,\r\n",
                        "    save_alt_val: bool = False,\r\n",
                        "):\r\n",
                        "    \"\"\"\r\n",
                        "    Load the specified pickle file if it exists.\r\n",
                        "    If not, use the provided function to generate and return\r\n",
                        "    an alternative value (the desired execution should be wrapped\r\n",
                        "    inside a lambda function to delay actual execution until needed).\r\n",
                        "    \"\"\"\r\n",
                        "    if os.path.exists(path_to_file):\r\n",
                        "        with open(path_to_file, \"rb\") as fp:\r\n",
                        "            file_value = pickle.load(fp)\r\n",
                        "        return file_value\r\n",
                        "    else:\r\n",
                        "        alt_value = alt_val_func()\r\n",
                        "        if save_alt_val is True:\r\n",
                        "            # Store value to avoid recompute across test cases\r\n",
                        "            with open(path_to_file, \"wb\") as fp:\r\n",
                        "                pickle.dump(alt_value, fp)\r\n",
                        "        return alt_value\r\n",
                        "\r\n",
                        "\r",
                        "\r\n",
                        "class TestIrisPipeline(unittest.TestCase):\r\n",
                        "    art_pkl_dir: Path\r\n",
                        "\r\n",
                        "    def setUp(self) -> None:\r\n",
                        "        # Add any processes to execute before each test in this class\r\n",
                        "        pass\r\n",
                        "\r\n",
                        "    def tearDown(self) -> None:\r\n",
                        "        # Add any processes to execute after each test in this class\r\n",
                        "        pass\r\n",
                        "\r\n",
                        "    @classmethod\r\n",
                        "    def setUpClass(cls) -> None:\r\n",
                        "        # Specify location where sample output files are stored for comparison\r\n",
                        "        cls.art_pkl_dir = Path(__file__).parent / \"sample_output\"\r\n",
                        "\r\n",
                        "        # Add any processes to execute once before all tests in this class run\r\n",
                        "        pass\r\n",
                        "\r\n",
                        "    @classmethod\r\n",
                        "    def tearDownClass(cls) -> None:\r\n",
                        "        # Add any processes to execute once after all tests in this class run\r\n",
                        "        pass\r\n",
                        "\r\n",
                        "    def test_get_iris_preprocessed(self) -> None:\r\n",
                        "        \"\"\"\r\n",
                        "        NOTE: The code below is provided as scaffold/template.\r\n",
                        "        Please adapt it to your specific testing context.\r\n",
                        "        [TODO: ADD LINK TO WEB DOCUMENTATION].\r\n",
                        "        \"\"\"\r\n",
                        "        # Prepare function input (adapt as needed)\r\n",
                        "        pass\r\n",
                        "\r\n",
                        "        # Generate function output (adapt as needed)\r\n",
                        "        sample_output_generated = get_iris_preprocessed()\r\n",
                        "\r\n",
                        "        # Perform tests (add/adapt as needed)\r\n",
                        "        sample_output_expected = safe_load_pickle(\r\n",
                        "            path_to_file=(self.art_pkl_dir / \"iris_preprocessed.pkl\"),\r\n",
                        "            alt_val_func=lambda: FileNotFoundError,\r\n",
                        "        )\r\n",
                        "        try:\r\n",
                        "            self.assertEqual(sample_output_generated, sample_output_expected)\r\n",
                        "        except Exception:\r\n",
                        "            warnings.warn(\r\n",
                        "                \"Test failed, but this may be due to our limited templating. \"\r\n",
                        "                \"Please adapt the test as needed.\"\r\n",
                        "            )\r\n",
                        "\r\n",
                        "    def test_get_iris_model(self) -> None:\r\n",
                        "        \"\"\"\r\n",
                        "        NOTE: The code below is provided as scaffold/template.\r\n",
                        "        Please adapt it to your specific testing context.\r\n",
                        "        [TODO: ADD LINK TO WEB DOCUMENTATION].\r\n",
                        "        \"\"\"\r\n",
                        "        # Prepare function input (adapt as needed)\r\n",
                        "        df = safe_load_pickle(\r\n",
                        "            path_to_file=(self.art_pkl_dir / \"iris_preprocessed.pkl\"),\r\n",
                        "            alt_val_func=lambda: get_iris_preprocessed(),\r\n",
                        "            save_alt_val=True,\r\n",
                        "        )\r\n",
                        "\r\n",
                        "        # Generate function output (adapt as needed)\r\n",
                        "        sample_output_generated = get_iris_model(df)\r\n",
                        "\r\n",
                        "        # Perform tests (add/adapt as needed)\r\n",
                        "        sample_output_expected = safe_load_pickle(\r\n",
                        "            path_to_file=(self.art_pkl_dir / \"iris_model.pkl\"),\r\n",
                        "            alt_val_func=lambda: FileNotFoundError,\r\n",
                        "        )\r\n",
                        "        try:\r\n",
                        "            self.assertEqual(sample_output_generated, sample_output_expected)\r\n",
                        "        except Exception:\r\n",
                        "            warnings.warn(\r\n",
                        "                \"Test failed, but this may be due to our limited templating. \"\r\n",
                        "                \"Please adapt the test as needed.\"\r\n",
                        "            )\r\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "%cat ./output/pipeline_basics/test_iris_pipeline.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6b4f39cc",
            "metadata": {},
            "source": [
                "As shown, the file contains test methods (e.g., ``TestIrisPipeline.test_get_iris_preprocessed()``) that\n",
                "each examine validity of the corresponding function in the module file (e.g., ``get_iris_preprocessed()``).\n",
                "Specifically, each test method attempts to check whether running the target function generates the same\n",
                "output (i.e., artifact value such as pre-processed data) as the original one saved in the artifact store\n",
                "(which gets copied over to a new local subfolder, e.g., ``./output/pipeline_basics/sample_output/``\n",
                "in this case, during pipeline generation)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f357912c",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "``safe_load_pickle()`` is a helper function (defined in the same testing file) that first tries to\n",
                "load the pickle file at ``path_to_file`` and, if the file does not exist, uses ``alt_val_func`` to\n",
                "re-calculate the value on the fly. If ``save_alt_val`` is set to ``True`` (default set to ``False``),\n",
                "the value produced from ``alt_val_func`` is saved at ``path_to_file`` so that it can be used by other\n",
                "related test methods without having to re-calculate it again (this \"recycling\" becomes critical when\n",
                "the value involves long computation).\n",
                "\n",
                "For ``alt_val_func``, the desired execution should be wrapped inside a lambda function to delay actual execution\n",
                "until needed (i.e., when ``safe_load_pickle()`` realizes that the pickle file does not exist and that it needs to\n",
                "re-calculate the value).\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1a10b035",
            "metadata": {},
            "source": [
                "As indicated by docstrings and comments such as ``adapt as needed``, these test methods are provided as\n",
                "a scaffold/template rather than a final version of pipeline testing. For instance, out of the box, all test methods\n",
                "rely on ``unittest``'s ``assertEqual()`` to evaluate equality between the generated vs. expected output values\n",
                "(of the function run), which may not be the right way to perform equality evaluation for certain objects such as\n",
                "a NumPy array (calling ``assertEqual()`` on two NumPy arrays would return an array of multiple Boolean values\n",
                "instead of a single Boolean value). Accordingly, the user is expected to customize the code to suit their own testing\n",
                "needs/contexts. For example, if the tested function's output is a NumPy array, then the user can replace the templated\n",
                "``self.assertEqual(sample_output_generated, sample_output_expected)`` with the customized ``assert all(sample_output_generated == sample_output_expected)``,\n",
                "which would result in proper equality evaluation."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9e1ab4eb",
            "metadata": {},
            "source": [
                "## Running Pipeline Test"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5926a544",
            "metadata": {},
            "source": [
                "With such limitations in templating, most test methods out of the box are bound to fail. However, to avoid any potential interference\n",
                "with the user's system, test failures are wrapped inside the ``try``-``except`` block, which makes all test methods run successfully\n",
                "without erroring out. Instead, the user is informed of failed test methods via warning messages that ask the user to check the code\n",
                "and adapt it if needed.\n",
                "\n",
                "Hence, for the ``iris_pipeline`` example discussed here, we get:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "10e31767",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "/Users/sangyoonpark/Projects/Linea/prod/lineapy/examples/tutorials/output/pipeline_basics\n",
                        "/Users/sangyoonpark/Projects/Linea/prod/lineapy/examples/tutorials/output/pipeline_basics/test_iris_pipeline.py:108: UserWarning: Test failed, but this may be due to our limited templating. Please adapt the test as needed.\n",
                        "  warnings.warn(\n",
                        "./Users/sangyoonpark/Projects/Linea/prod/lineapy/examples/tutorials/output/pipeline_basics/test_iris_pipeline.py:79: UserWarning: Test failed, but this may be due to our limited templating. Please adapt the test as needed.\n",
                        "  warnings.warn(\n",
                        ".\n",
                        "----------------------------------------------------------------------\n",
                        "Ran 2 tests in 0.231s\n",
                        "\n",
                        "OK\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "%cd ./output/pipeline_basics/\n",
                "!python -m unittest test_iris_pipeline.TestIrisPipeline"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "954f56eb",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-warning\">\n",
                "\n",
                "Tests may involve long compute and/or large storage, so please take care in running them.\n",
                "\n",
                "</div>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2f2a3e7a",
            "metadata": {},
            "source": [
                "## Adapting Pipeline Test"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8749a6b",
            "metadata": {},
            "source": [
                "As shown, both test methods \"failed\" (i.e., warning messages raised) for ``iris_pipeline``. This is not surprising because,\n",
                "again, the scaffold is relying on a naive mode of equality evaluation via ``unittest``'s ``assertEqual()``, which does not\n",
                "work for more sophisticated object types such as ``pandas.DataFrame`` and ``sklearn.linear_model.LinearRegression``.\n",
                "For more proper equality evaluation, we may replace existing ``try``-``except`` blocks with new ``assert`` statements,\n",
                "like so:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "641265a7",
            "metadata": {},
            "source": [
                "```python\n",
                "# ./output/pipeline_basics/test_iris_pipeline.py\n",
                "\n",
                "import os\n",
                "import pickle\n",
                "import unittest\n",
                "import warnings\n",
                "from pathlib import Path\n",
                "from typing import Callable\n",
                "\n",
                "from iris_pipeline_module import get_iris_model, get_iris_preprocessed\n",
                "\n",
                "[...]\n",
                "\n",
                "class TestIrisPipeline(unittest.TestCase):\n",
                "\n",
                "    [...]\n",
                "\n",
                "    def test_get_iris_preprocessed(self) -> None:\n",
                "        \"\"\"\n",
                "        NOTE: The code below is provided as scaffold/template.\n",
                "        Please adapt it to your specific testing context.\n",
                "        \"\"\"\n",
                "        # Prepare function input (adapt as needed)\n",
                "        pass\n",
                "\n",
                "        # Generate function output (adapt as needed)\n",
                "        sample_output_generated = get_iris_preprocessed()\n",
                "\n",
                "        # Perform tests (add/adapt as needed)\n",
                "        sample_output_expected = safe_load_pickle(\n",
                "            path_to_file=(self.art_pkl_dir / \"iris_preprocessed.pkl\"),\n",
                "            alt_val_func=lambda: FileNotFoundError,\n",
                "        )\n",
                "        assert sample_output_generated.equals(sample_output_expected)\n",
                "\n",
                "    def test_get_iris_model(self) -> None:\n",
                "        \"\"\"\n",
                "        NOTE: The code below is provided as scaffold/template.\n",
                "        Please adapt it to your specific testing context.\n",
                "        \"\"\"\n",
                "        # Prepare function input (adapt as needed)\n",
                "        df = safe_load_pickle(\n",
                "            path_to_file=(self.art_pkl_dir / \"iris_preprocessed.pkl\"),\n",
                "            alt_val_func=lambda: get_iris_preprocessed(),\n",
                "            save_alt_val=True,\n",
                "        )\n",
                "\n",
                "        # Generate function output (adapt as needed)\n",
                "        sample_output_generated = get_iris_model(df)\n",
                "\n",
                "        # Perform tests (add/adapt as needed)\n",
                "        sample_output_expected = safe_load_pickle(\n",
                "            path_to_file=(self.art_pkl_dir / \"iris_model.pkl\"),\n",
                "            alt_val_func=lambda: FileNotFoundError,\n",
                "        )\n",
                "        assert sample_output_generated.intercept_ == sample_output_expected.intercept_\n",
                "        assert all(sample_output_generated.coef_ == sample_output_expected.coef_)\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6bb533c6",
            "metadata": {},
            "source": [
                "With these changes, running the test would result in success without any warning messages raised."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8d57ec9e",
            "metadata": {},
            "source": [
                "Note that the user is free to use their own input and (expected) output values to suit their testing needs.\n",
                "For instance, with the example above, say the user happens to have new pre-processed data stored as a CSV file,\n",
                "along with the corresponding model's parameter estimates recorded. Then, the user may further customize testing of\n",
                "``get_iris_model()`` as the following:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "46c4207a",
            "metadata": {},
            "source": [
                "```python\n",
                "# ./output/pipeline_basics/test_iris_pipeline.py\n",
                "\n",
                "import os\n",
                "import pickle\n",
                "import unittest\n",
                "import warnings\n",
                "from pathlib import Path\n",
                "from typing import Callable\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from iris_pipeline_module import get_iris_model, get_iris_preprocessed\n",
                "\n",
                "[...]\n",
                "\n",
                "class TestIrisPipeline(unittest.TestCase):\n",
                "\n",
                "    [...]\n",
                "\n",
                "    def test_get_iris_model(self) -> None:\n",
                "        \"\"\"\n",
                "        NOTE: The code below is provided as scaffold/template.\n",
                "        Please adapt it to your specific testing context.\n",
                "        \"\"\"\n",
                "        # Prepare function input (adapt as needed)\n",
                "        df = pd.read_csv(\"some_path_or_url/new_iris_preprocessed.csv\")\n",
                "\n",
                "        # Generate function output (adapt as needed)\n",
                "        sample_output_generated = get_iris_model(df)\n",
                "\n",
                "        # Perform tests (add/adapt as needed)\n",
                "        assert round(sample_output_generated.intercept_, 2) == 3.24\n",
                "        assert all(np.round(sample_output_generated.coef_, 2) == [0.78, -1.5, -1.84])\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b4e10f6c",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\">\n",
                "\n",
                "In adapting the testing scaffold/template, we can go beyond equality evaluation. For instance, if the tested function outputs\n",
                "a model, we can check whether the model behaves \"reasonably\" by feeding it with particular input values and observing whether\n",
                "it returns output values within a certain range. This type of testing is especially valuable for models involving inherent stochasticity,\n",
                "where the same procedure does not necessarily guarantee exactly identical results.\n",
                "\n",
                "</div>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}