# Contributing

This repository contains a few different components:

- A **transformer** which traces the Python AST and generates a graph from it, using the tracer.
- A **tracer** that adds nodes to the graph (and then executes them with the executor)
- A **dataflow graph** which is stored in SQLite and represents a Python execution
- An **executor** which takes the graph and can run it as Python code

## First-time Setup

To run our tests, first download the submodules:

```
git submodule update --init --recursive.
```

### Conda

```bash
conda create --name lineapy python=3.9 \
    postgresql \
    graphviz \
    cmake # needed for building deps of numpy tutorial on mac
conda activate lineapy
pip install -r requirements.txt
pip install -e .
```
(We support python 3.8+ for now and you can initialize a conda environment with python 3.8 as well if you desire)

We also support using [`pre-commit`](https://github.com/pre-commit/pre-commit)
to run linting before committing:

```bash
# Installs pre commit hook to run linting before commit:
pre-commit install
# To manually run hooks:
pre-commit
# To force a run even when there are no changes
pre-commit run --all-files
```

Note that the pre-commit hook does not run the tests, since these are time
consuming and you might not want to have to wait to run them on every commit.

The pre commit config also pins the versions of the packages. To update them to
the latest, run `pre-commit autoupdate`.

### Docker + Makefile

To build the Lineapy container, run `make build` (you can pass in arguments with `args=`, i.e. `make build args=--no-cache`)
To open bash within the container, run `make bash`. One can either use bash for dev or can connect to remote runtimes inside a container using extensions available for the editor of choice.
`make tests` executes the test suite.

To build Lineapy contained with Airflow, run `make build-airflow`. `make tests-airflow` runs airflow tests.
`make airflow-up` is one command that will bring up a standalone local Airflow server on port 8080.
Login and password will be printed on command line output. Please note that this mode used SQLite DB and is not meant for heavy workloads.

### Codespaces

You can also run this in Codespaces.

To test this the container, you can use:

```bash
docker build -t lineapy -f .devcontainer/Dockerfile .
docker run --rm -it -p 8080:8080 -p 8888:8888 -v $PWD:/workspaces/lineapy lineapy
```

## Debugging (in VSC)

`.vscode/launch.json` has a VSC debug configuration for `lineapy` which executes `lineapy --slice "p value" tests/housing.py` through VSC "Run and Debug" dialog.

## Tests

```bash
mypy .
black --line-length 79 --check .
pytest tests
```

If using docker, please add appropriate tests and ensure all tests are working using
`make test`. Any args to pytest can be passed using args="xxx". Eg, individual tests can be run using `make test args="<path_to_test_file>"`.

Some tests have been marked "slow". These typically take > 0.5s and can be skipped by passing the args `-m "not slow"` when running pytest.

We also added some tests which run airflow to verify that it works on the code we produce. These also take a lot longer, they create their own virtualenv
with airflow in it, and create a new airflow DB. By default, those are not run. To run them, use `-m "airflow"` when running pytest.

### Logging

We have logging set up as well, which can be printed while running the tests
to help with debugging:

```bash
pytest --log-cli-level INFO
```

If you would like to see the logs pretty printed, using
[Rich's custom log handler](https://rich.readthedocs.io/en/stable/logging.html)
you have to disable pytests built in handler disable its stdout capturing:

```bash
pytest -p no:logging -s
```

### Snapshots

Some tests use use [`syrupy`](https://github.com/tophat/syrupy) for snapshot test, to make it easier to update generate code and graphs.
If you mean to change the tracing or graph spec, or added a new test that uses it, then run `pytest --snapshot-update` to update the saved snapshots.
If using docker, you can use `make test args="--snapshot-update"` to update snapshots.

We also generate snapshots for a visualization of the graph as SVG. These are
only used to help in the diffs, not for testing. They will be regenerated by
default only when a snapshot is updated or created. To force them to
regenerate, use the `--svg-update` CLI option. They are not regenerated by
default, since their source is not deterministic.


### XFail

Also we use [pytest's xfail](https://docs.pytest.org/en/latest/how-to/skipping.html#xfail-mark-test-functions-as-expected-to-fail) to mark tests that are expected to fail, because of a known bug. To have them run anyway, run `--run-xfail`.

### Notebooks

We currently have notebooks that are also evaluated in the tests, and the
outputs are compared.

If you want to re-run all the notebooks and update their outputs, run:

```bash
make notebooks
# You can also re-run and save a particular notebook with
make tests/notebook/test_visualize.ipynb
```

Or you can open it in a notebook UI (JupyterLab, JupyterNotebook, VS Code, etc.)
and re-run it manually

### Airflow

Sliced code can be exported to an Airflow DAG using the following command:

```
lineapy tests/housing.py --slice "p value" --airflow sliced_housing_dag
```

This creates a `sliced_housing_dag.py` file in the current dir. It can be executed with:

```
airflow db init
airflow dags test sliced_housing_dag_dag $(date '+%Y-%m-%d') -S .
```

## Visual Graphs

Sometimes it's helpful to see a visual representation of the graph
and the tracers state, while debugging a test. Run the tests with `--visualize`
to have it save a `tracer.pdf` file whenever it run an execution.

Note: This requires graphviz to be installed.

## Performance Profiling

We have had luck using the [py-spy](https://github.com/benfred/py-spy) tool,
which runs your Python script in a separate process and samples it, to
profile our tests to get a rough sense of how long things take:

```bash
# Run with sudo so it can inspect the subprocess
sudo py-spy record \
    # Save as speedscope so we can load in the browser
    --format speedscope \
    # Group by function name, instead of line number
    --function \
    # Increase the sampling rate from 100 to 200 times per second
    -r 200  -- pytest tests/
```

After creating your trace, you can load it [in
Speedscope](https://www.speedscope.app/).

In this example, we are inspecting calls to `transform`.
We see that it cumulatively takes up 12% of total time and that most of the time inside of it is spent visiting imports, as well as committing to the DB:

<img width="2560" alt="Screen Shot 2021-10-12 at 2 29 10 PM" src="https://user-images.githubusercontent.com/1186124/137037002-18f29bd8-db02-4924-9855-5f3db9d2d0ee.png">


## Building docs

When you are in the root directory, running the following command

```bash
sphinx-autobuild docs/source/ docs/build/html/
```

And any changes in the rst files in the `/docs` directory will be detected and
and the html refreshed. However, changes in the doc strings in code will not be
picked up, and you'd have to run the command again to refresh.

## Some utilities

**Inspecting AST**

If you want to inspect the AST of some Python code for debugging, you can run:

```bash
./tests/tools/print_ast.py 'hi(a=10)'
```

**Verifying the specs**

```bash
./tests/tools/test_validate_annotation_spec.py
```

## Debug Flags

By default, linea will rewrite any exceptions raised during the normal
execution of users code to attempt to match Python's behavior. To disable our
custom exception handling, set the `LINEA_NO_EXCEPTIONS` environment variable
to any value.

## Before Committing

Please ensure linting and `typecheck`s are done before opening a PR. When using docker, this can be done using `make lint` and `make typecheck` respectively. A pre-commit hook that runs `make blackfix lint typecheck build test` will fix any fixable issues and ensure build and test works.

## Github Actions

The tests are run on Github Actions. If you are trying to debug a failure that happens on Github Actions, you can try using [`act`](https://github.com/nektos/act), which will run it locally through docker:

```bash
brew install act
act
# When it prompts, the "medium" image seems to work out alright.
```
