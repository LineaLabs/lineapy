{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2431827-e356-46f4-85e9-8b58a4616111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LineaArtifact(name='trainined_model', _version=7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1=1 # training_data\n",
    "n2=2 # initialize vector encoder\n",
    "n3 = n2 + n1 # fit training_data and create new copy of vector encoder\n",
    "lineapy.save(n3, \"vector_encoder\") # saved vector encoder\n",
    "n1 = n1+1 # continue modifying training data\n",
    "lineapy.save(n1,\"cleaned_training\")# save cleaned training data\n",
    "n4 = 1 # initialize model\n",
    "n4 = n4+n1 # train model using cleaned training data\n",
    "lineapy.save(n4, \"trainined_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a5aebf-fcbd-40a5-b260-58115b016f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated module file: airflow/dags/data_pipeline_sample_module.py                                                                     \n",
      "Generated requirements file: airflow/dags/data_pipeline_sample_requirements.txt                                                        \n",
      "Generated DAG file: airflow/dags/data_pipeline_sample_dag.py                                                                           \n",
      "Generated Docker file: airflow/dags/data_pipeline_sample_Dockerfile                                                                    \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = lineapy.to_pipeline(\n",
    "    [\"cleaned_training\",\"vector_encoder\", \"trainined_model\"], \n",
    "    framework=\"AIRFLOW\",\n",
    "    pipeline_name=\"data_pipeline_sample\",\n",
    "    dependencies={ \"trainined_model\": { \"cleaned_training\" } },\n",
    "    output_dir=\"./airflow/dags/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1bb5c1-0263-462e-a6bb-2843615d98f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_n1_for_artifact_vector_encoder_and_downstream():\n",
      "    n1 = 1  # training_data\n",
      "    return n1\n",
      "\n",
      "\n",
      "def get_vector_encoder(n1):\n",
      "    n2 = 2  # initialize vector encoder\n",
      "    n3 = n2 + n1  # fit training_data and create new copy of vector encoder\n",
      "    return n3\n",
      "\n",
      "\n",
      "def get_cleaned_training():\n",
      "    n1 = n1 + 1  # continue modifying training data\n",
      "    return n1\n",
      "\n",
      "\n",
      "def get_trainined_model(n1):\n",
      "    n4 = 1  # initialize model\n",
      "    n4 = n4 + n1  # train model using cleaned training data\n",
      "    return n4\n",
      "\n",
      "\n",
      "def run_session_including_vector_encoder():\n",
      "    # Given multiple artifacts, we need to save each right after\n",
      "    # its calculation to protect from any irrelevant downstream\n",
      "    # mutations (e.g., inside other artifact calculations)\n",
      "    import copy\n",
      "\n",
      "    artifacts = dict()\n",
      "    n1 = get_n1_for_artifact_vector_encoder_and_downstream()\n",
      "    n3 = get_vector_encoder(n1)\n",
      "    artifacts[\"vector_encoder\"] = copy.deepcopy(n3)\n",
      "    n1 = get_cleaned_training()\n",
      "    artifacts[\"cleaned_training\"] = copy.deepcopy(n1)\n",
      "    n4 = get_trainined_model(n1)\n",
      "    artifacts[\"trainined_model\"] = copy.deepcopy(n4)\n",
      "    return artifacts\n",
      "\n",
      "\n",
      "def run_all_sessions():\n",
      "    artifacts = dict()\n",
      "    artifacts.update(run_session_including_vector_encoder())\n",
      "    return artifacts\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Edit this section to customize the behavior of artifacts\n",
      "    artifacts = run_all_sessions()\n",
      "    print(artifacts)\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"cat {directory}/data_pipeline_sample_module.py\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a101466-7692-4430-8414-4d1a21026eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated module file: airflow/dags/data_pipeline_sample_module.py                                                                     \n",
      "Generated requirements file: airflow/dags/data_pipeline_sample_requirements.txt                                                        \n",
      "Generated DAG file: airflow/dags/data_pipeline_sample_dag.py                                                                           \n",
      "Generated Docker file: airflow/dags/data_pipeline_sample_Dockerfile                                                                    \n",
      "/Users/simba/Projects/lineapy/lineapy/api/models/pipeline.py:88: UserWarning: Reuse of pre-computed artifacts is currently NOT supported for Airflow DAGs. Hence, the generated Airflow DAG file would recompute all artifacts in the pipeline.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = lineapy.to_pipeline(\n",
    "    [\"cleaned_training\",\"vector_encoder\", \"trainined_model\"], \n",
    "    framework=\"AIRFLOW\",\n",
    "    pipeline_name=\"data_pipeline_sample\",\n",
    "    dependencies={ \"trainined_model\": { \"cleaned_training\" } },\n",
    "    reuse_pre_computed_artifacts=[\"vector_encoder\"],\n",
    "    output_dir=\"./airflow/dags/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcad56a8-194e-45ae-97b4-7e57011ab028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_vector_encoder():\n",
      "    import lineapy\n",
      "\n",
      "    n3 = lineapy.get(\"vector_encoder\", 7).get_value()\n",
      "    return n3\n",
      "\n",
      "\n",
      "def get_cleaned_training():\n",
      "    n1 = n1 + 1  # continue modifying training data\n",
      "    return n1\n",
      "\n",
      "\n",
      "def get_trainined_model(n1):\n",
      "    n4 = 1  # initialize model\n",
      "    n4 = n4 + n1  # train model using cleaned training data\n",
      "    return n4\n",
      "\n",
      "\n",
      "def run_session_including_vector_encoder():\n",
      "    # Given multiple artifacts, we need to save each right after\n",
      "    # its calculation to protect from any irrelevant downstream\n",
      "    # mutations (e.g., inside other artifact calculations)\n",
      "    import copy\n",
      "\n",
      "    artifacts = dict()\n",
      "    n3 = get_vector_encoder()\n",
      "    artifacts[\"vector_encoder\"] = copy.deepcopy(n3)\n",
      "    n1 = get_cleaned_training()\n",
      "    artifacts[\"cleaned_training\"] = copy.deepcopy(n1)\n",
      "    n4 = get_trainined_model(n1)\n",
      "    artifacts[\"trainined_model\"] = copy.deepcopy(n4)\n",
      "    return artifacts\n",
      "\n",
      "\n",
      "def run_all_sessions():\n",
      "    artifacts = dict()\n",
      "    artifacts.update(run_session_including_vector_encoder())\n",
      "    return artifacts\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Edit this section to customize the behavior of artifacts\n",
      "    artifacts = run_all_sessions()\n",
      "    print(artifacts)\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"cat {directory}/data_pipeline_sample_module.py\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c8a0d-8ac0-49bb-a896-62aa4c38e42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
