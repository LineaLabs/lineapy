{% extends "airflow_base_dag.jinja" %}

{% block plugin_import_block %}
import {{ MODULE_NAME }}
import pickle
import pathlib
from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.python_operator import PythonOperator
{% endblock %}

{% block plugin_dag_block %}
def dag_setup():
    pickle_folder = pathlib.Path('/tmp').joinpath('{{ DAG_NAME }}')
    if not pickle_folder.exists():
        pickle_folder.mkdir()

def dag_teardown():
    pickle_files = pathlib.Path('/tmp').joinpath('{{ DAG_NAME }}').glob('*.pickle')
    for f in pickle_files:
        f.unlink()
{% for TASK_DEF in task_definitions %}
{{ TASK_DEF }} 
{% endfor %}
{% endblock %}

{% block plugin_tasks_block %}

default_dag_args = {
    "owner": "{{ OWNER }}",
    "retries": {{ RETRIES }},
    "start_date": {{ START_DATE }},{%- if (dag_params != '"params":{}') %}    {{dag_params}},{%- endif -%}
}

with DAG(
    dag_id="{{ DAG_NAME }}_dag",
    schedule_interval="{{ SCHEDULE_INTERVAL }}",
    max_active_runs={{ MAX_ACTIVE_RUNS }},
    catchup={{ CATCHUP }},
    default_args=default_dag_args,
) as dag:

    setup = PythonOperator(
        task_id="dag_setup",
        python_callable=dag_setup,
    )

    teardown = PythonOperator(
        task_id="dag_teardown",
        python_callable=dag_teardown,
    )

{% for TASKDESCRIPTION in tasks %}
{% if TASKDESCRIPTION[1] is none %}
    {{ TASKDESCRIPTION[0] }} = PythonOperator(
        task_id="{{ TASKDESCRIPTION[0] }}_task", python_callable=task_{{ TASKDESCRIPTION[0] }},
    )
{% else %}
    {{ TASKDESCRIPTION[0] }} = PythonOperator(
        task_id="{{ TASKDESCRIPTION[0] }}_task", python_callable=task_{{ TASKDESCRIPTION[0] }}, {{TASKDESCRIPTION[1]}},
    )
{% endif %}
{% endfor %}
{% if task_dependencies is not none %}
{% for TASK_DEPENDENCIES in task_dependencies %}
    {{TASK_DEPENDENCIES}}
{% endfor %}
{%endif %}
{% endblock %}

