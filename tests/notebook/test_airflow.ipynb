{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "3054022d-ea1b-4422-bd97-b323b72b0322",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Generated module file: ~/airflow/dags/z_module.py                                                                                                                                                         \n",
                        "Generated requirements file: ~/airflow/dags/z_requirements.txt                                                                                                                                            \n",
                        "Generated test scaffold file: ~/airflow/dags/test_z.py                                                                                                                                                 \n",
                        "/Users/andrewcui/projects/lineapy/lineapy/plugins/pipeline_writers.py:148: UserWarning: Generated tests are provided as template/scaffold to start with only; please modify them to suit your testing needs. Also, tests may involve long compute and/or large storage, so please take care in running them.\n",
                        "  warnings.warn(\n",
                        "Generated DAG file: ~/airflow/dags/z_dag.py                                                                                                                                                               \n",
                        "Generated Docker file: ~/airflow/dags/z_Dockerfile                                                                                                                                                        \n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "import lineapy\n",
                "\n",
                "x = 100\n",
                "y = 10\n",
                "\n",
                "z = [x]\n",
                "art = lineapy.save(z, \"z\")\n",
                "pipeline_dir = lineapy.to_pipeline([art.name], framework='AIRFLOW', output_dir=\"~/airflow/dags\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "94daffd2-f19f-4b0e-bbe3-8e94024b405c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "def get_z():\n",
                        "    x = 100\n",
                        "    z = [x]\n",
                        "    return z\n",
                        "\n",
                        "\n",
                        "def run_session_including_z():\n",
                        "    # Given multiple artifacts, we need to save each right after\n",
                        "    # its calculation to protect from any irrelevant downstream\n",
                        "    # mutations (e.g., inside other artifact calculations)\n",
                        "    import copy\n",
                        "\n",
                        "    artifacts = dict()\n",
                        "    z = get_z()\n",
                        "    artifacts[\"z\"] = copy.deepcopy(z)\n",
                        "    return artifacts\n",
                        "\n",
                        "\n",
                        "def run_all_sessions():\n",
                        "    artifacts = dict()\n",
                        "    artifacts.update(run_session_including_z())\n",
                        "    return artifacts\n",
                        "\n",
                        "\n",
                        "if __name__ == \"__main__\":\n",
                        "    # Edit this section to customize the behavior of artifacts\n",
                        "    artifacts = run_all_sessions()\n",
                        "    print(artifacts)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# NBVAL_IGNORE_OUTPUT\n",
                "module_path = pipeline_dir/\"z_module.py\"\n",
                "print(module_path.read_text())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "225db4ee-c1ce-437a-b862-f2819bc05335",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "import pathlib\n",
                        "import pickle\n",
                        "\n",
                        "import z_module\n",
                        "from airflow import DAG\n",
                        "from airflow.operators.python_operator import PythonOperator\n",
                        "from airflow.utils.dates import days_ago\n",
                        "\n",
                        "\n",
                        "def dag_setup():\n",
                        "    pickle_folder = pathlib.Path(\"/tmp\").joinpath(\"z\")\n",
                        "    if not pickle_folder.exists():\n",
                        "        pickle_folder.mkdir()\n",
                        "\n",
                        "\n",
                        "def dag_teardown():\n",
                        "    pickle_files = pathlib.Path(\"/tmp\").joinpath(\"z\").glob(\"*.pickle\")\n",
                        "    for f in pickle_files:\n",
                        "        f.unlink()\n",
                        "\n",
                        "\n",
                        "def task_z():\n",
                        "\n",
                        "    z = z_module.get_z()\n",
                        "\n",
                        "    pickle.dump(z, open(\"/tmp/z/variable_z.pickle\", \"wb\"))\n",
                        "\n",
                        "\n",
                        "default_dag_args = {\n",
                        "    \"owner\": \"airflow\",\n",
                        "    \"retries\": 2,\n",
                        "    \"start_date\": days_ago(1),\n",
                        "}\n",
                        "\n",
                        "with DAG(\n",
                        "    dag_id=\"z_dag\",\n",
                        "    schedule_interval=\"*/15 * * * *\",\n",
                        "    max_active_runs=1,\n",
                        "    catchup=False,\n",
                        "    default_args=default_dag_args,\n",
                        ") as dag:\n",
                        "\n",
                        "    setup = PythonOperator(\n",
                        "        task_id=\"dag_setup\",\n",
                        "        python_callable=dag_setup,\n",
                        "    )\n",
                        "\n",
                        "    teardown = PythonOperator(\n",
                        "        task_id=\"dag_teardown\",\n",
                        "        python_callable=dag_teardown,\n",
                        "    )\n",
                        "\n",
                        "    z = PythonOperator(\n",
                        "        task_id=\"z_task\",\n",
                        "        python_callable=task_z,\n",
                        "    )\n",
                        "\n",
                        "    setup >> z\n",
                        "\n",
                        "    z >> teardown\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "dag_path = pipeline_dir/\"z_dag.py\"\n",
                "print(dag_path.read_text())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "f046477f-d97e-4224-98bc-0682061271e2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cleanup pipeline files\n",
                "import shutil\n",
                "shutil.rmtree(pipeline_dir)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}